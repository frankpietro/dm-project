{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b99d6b",
   "metadata": {},
   "source": [
    "# Data Mining Project\n",
    "### Giorgio Donati, g.donati24@studenti.unipi.it\n",
    "### Pietro Francaviglia, p.francaviglia1@studenti.unipi.it\n",
    "#### A.Y. 2021-2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defe5e4",
   "metadata": {},
   "source": [
    "## Libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d45a9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import itertools\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from t3_constants import *\n",
    "from t3_utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PICKLE_FOLDER}{LABELLED}{USER_DF}.pkl', 'rb') as f:\n",
    "    u_df = pickle.load(f)\n",
    "\n",
    "with open(f'{PICKLE_FOLDER}{PURE}{LABELLED}{USER_DF}.pkl', 'rb') as f:\n",
    "    pure_u_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 795 entries, 1 to 823\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   item_count            795 non-null    int64  \n",
      " 1   item_dist_count       795 non-null    int64  \n",
      " 2   max_items_per_b       795 non-null    int64  \n",
      " 3   price_entropy         795 non-null    float64\n",
      " 4   max_item_dist_per_b   795 non-null    int64  \n",
      " 5   total_price           795 non-null    float64\n",
      " 6   basket_count          795 non-null    int64  \n",
      " 7   category_count        795 non-null    int64  \n",
      " 8   shop_count            795 non-null    int64  \n",
      " 9   avg_items_per_basket  795 non-null    float64\n",
      " 10  avg_baskets_per_d     795 non-null    float64\n",
      " 11  label                 766 non-null    object \n",
      "dtypes: float64(4), int64(7), object(1)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "u_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 9, 7, 1, 2, 2, 5, 2, 7, 1, 2, 0, 7, 0, 7, 0, 1, 2, 7, 0, 4, 4,\n",
       "       5, 5, 1, 4, 4, 3, 2, 3, 1, 2, 1, 3, 3, 5, 2, 1, 7, 0, 8, 3, 7, 6,\n",
       "       2, 3, 0, 5, 0, 0, 0, 2, 0, 1, 0, 2, 5, 0, 5, 3, 6, 4, 4, 2, 7, 1,\n",
       "       4, 7, 7, 4, 1, 3, 5, 4, 6, 4, 3, 6, 1, 7, 6, 9, 7, 4, 2, 2, 2, 1,\n",
       "       1, 0, 4, 1, 1, 6, 3, 1, 0, 2, 3, 2, 6, 3, 1, 7, 5, 8, 2, 0, 0, 4,\n",
       "       7, 5, 3, 4, 1, 1, 1, 8, 1, 4, 6, 6, 1, 2, 3, 1, 6, 1, 3, 4, 6, 3,\n",
       "       5, 4, 3, 0, 4, 1, 4, 0, 1, 0, 4, 0, 0, 7, 6, 1, 6, 7, 7, 0, 2, 5,\n",
       "       2, 4, 7, 2, 5, 1, 0, 2, 0, 5, 6, 0, 3, 3, 5, 2, 6, 5, 0, 7, 5, 6,\n",
       "       4, 0, 3, 0, 4, 0, 2, 7, 0, 2, 5, 1, 1, 0, 1, 3, 3, 6, 5, 3, 4, 0,\n",
       "       2, 5, 0, 4, 0, 4, 3, 2, 7, 3, 5, 7, 6, 2, 4, 1, 8, 3, 1, 7, 4, 5,\n",
       "       2, 1, 7, 6, 2, 5, 4, 5, 4, 6, 8, 4, 7, 8, 6, 3, 5, 5, 3, 4, 7, 2,\n",
       "       3, 2, 0, 7, 1, 5, 6, 1, 0, 6, 9, 3, 0, 1, 6, 0, 0, 0, 3, 1, 6, 3,\n",
       "       5, 1, 0, 2, 1, 3, 6, 0, 3, 4, 0, 0, 5, 1, 5, 8, 4, 7, 0, 0, 4, 7,\n",
       "       3, 3, 1, 6, 0, 5, 5, 5, 2, 5, 0, 1, 1, 0, 0, 8, 7, 1, 3, 6, 4, 0,\n",
       "       7, 8, 1, 3, 6, 4, 5, 0, 4, 1, 4, 5, 0, 1, 7, 6, 4, 0, 5, 2, 4, 3,\n",
       "       3, 0, 1, 3, 3, 8, 1, 6, 7, 1, 6, 8, 1, 4, 5, 6, 3, 6, 4, 0, 6, 1,\n",
       "       1, 0, 0, 1, 0, 5, 6, 1, 0, 8, 3, 5, 7, 1, 2, 2, 4, 4, 3, 6, 0, 1,\n",
       "       2, 7, 3, 3, 0, 1, 3, 1, 7, 7, 0, 0, 6, 0, 5, 0, 5, 5, 8, 1, 2, 0,\n",
       "       0, 1, 2, 2, 6, 1, 5, 2, 8, 4, 7, 0, 5, 4, 1, 4, 3, 6, 7, 5, 9, 5,\n",
       "       6, 1, 6, 0, 1, 0, 6, 3, 2, 5, 7, 5, 1, 2, 0, 7, 2, 4, 5, 5, 2, 2,\n",
       "       2, 0, 4, 1, 5, 2, 1, 1, 8, 4, 4, 7, 3, 4, 8, 4, 5, 4, 1, 0, 4, 5,\n",
       "       3, 7, 8, 3, 3, 5, 0, 1, 4, 0, 0, 1, 6, 2, 1, 2, 6, 2, 3, 5, 3, 5,\n",
       "       5, 7, 4, 5, 0, 3, 0, 2, 2, 0, 2, 3, 2, 1, 6, 1, 5, 0, 2, 0, 3, 1,\n",
       "       1, 8, 1, 1, 0, 0, 2, 7, 4, 5, 0, 4, 7, 1, 2, 2, 0, 4, 6, 0, 2, 3,\n",
       "       9, 1, 0, 0, 2, 1, 2, 0, 0, 0, 3, 8, 0, 1, 0, 3, 6, 1, 3, 3, 7, 7,\n",
       "       3, 6, 4, 0, 7, 9, 8, 3, 7, 7, 0, 1, 1, 6, 4, 2, 2, 3, 4, 2, 3, 1,\n",
       "       5, 0, 2, 3, 7, 8, 0, 1, 5, 3, 2, 2, 6, 0, 1, 4, 3, 2, 2, 2, 6, 7,\n",
       "       1, 3, 0, 2, 8, 2, 9, 6, 7, 3, 3, 1, 0, 0, 3, 5, 2, 4])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    u_df[u_df[LAB].notna()].drop(columns=[LAB]),\n",
    "    u_df[u_df[LAB].notna()][LAB],\n",
    "    test_size=0.2,\n",
    "    stratify=u_df[u_df[LAB].notna()][LAB])\n",
    "x = train_x.values\n",
    "y = train_y.values.ravel().astype(int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, X: np.ndarray, y: np.ndarray, n_splits: int) -> np.ndarray:\n",
    "    \"\"\"Return validation scores across the k folds of cross-validation.\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=0, shuffle=True)\n",
    "    val_score = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        model.fit(X[train_index], y[train_index].ravel())\n",
    "        val_score.append(model.score(X[test_index], y[test_index].ravel() + 1))\n",
    "    return np.array(val_score)\n",
    "\n",
    "def cross_validation_summary(model, X: np.ndarray, y: np.ndarray, n_splits: int) -> np.ndarray:\n",
    "    \"\"\"Returns validation accuracy score of model (mean and std over all the splits).\"\"\"\n",
    "    val_score = cross_validation(model, X, y, n_splits)\n",
    "    return val_score.mean(), val_score.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'unknown' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m criterion, min_impurity_decrease, min_samples_leaf \u001b[39min\u001b[39;00m combinations:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=12'>13</a>\u001b[0m     model \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mDecisionTreeClassifier(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=13'>14</a>\u001b[0m         criterion\u001b[39m=\u001b[39mcriterion,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=14'>15</a>\u001b[0m         min_impurity_decrease\u001b[39m=\u001b[39mmin_impurity_decrease,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=15'>16</a>\u001b[0m         min_samples_leaf\u001b[39m=\u001b[39mmin_samples_leaf,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=16'>17</a>\u001b[0m         random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=17'>18</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=18'>19</a>\u001b[0m     mean_val_score, std_val_score \u001b[39m=\u001b[39m cross_validation_summary(model, x, y, \u001b[39m5\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=19'>20</a>\u001b[0m     res \u001b[39m=\u001b[39m criterion, min_impurity_decrease, min_samples_leaf, mean_val_score, std_val_score\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=20'>21</a>\u001b[0m     results\u001b[39m.\u001b[39mappend(res)\n",
      "\u001b[1;32m/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb Cell 8\u001b[0m in \u001b[0;36mcross_validation_summary\u001b[0;34m(model, X, y, n_splits)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcross_validation_summary\u001b[39m(model, X: np\u001b[39m.\u001b[39mndarray, y: np\u001b[39m.\u001b[39mndarray, n_splits: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=10'>11</a>\u001b[0m     \u001b[39m\"\"\"Returns validation accuracy score of model (mean and std over all the splits).\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=11'>12</a>\u001b[0m     val_score \u001b[39m=\u001b[39m cross_validation(model, X, y, n_splits)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m val_score\u001b[39m.\u001b[39mmean(), val_score\u001b[39m.\u001b[39mstd()\n",
      "\u001b[1;32m/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb Cell 8\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, X, y, n_splits)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=2'>3</a>\u001b[0m skf \u001b[39m=\u001b[39m StratifiedKFold(n_splits\u001b[39m=\u001b[39mn_splits, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=3'>4</a>\u001b[0m val_score \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m train_index, test_index \u001b[39min\u001b[39;00m skf\u001b[39m.\u001b[39msplit(X, y):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=5'>6</a>\u001b[0m     model\u001b[39m.\u001b[39mfit(X[train_index], y[train_index]\u001b[39m.\u001b[39mravel())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hdjdox/Documents/e_education/magistrale/data_mining/dm-project/DM_DonatiFrancaviglia_TASK3/predictive_labelling.ipynb#ch0000005?line=6'>7</a>\u001b[0m     val_score\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mscore(X[test_index], y[test_index]\u001b[39m.\u001b[39mravel() \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py:340\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m n_samples:\n\u001b[1;32m    333\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    334\u001b[0m         (\n\u001b[1;32m    335\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot have number of splits n_splits=\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m greater\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m than the number of samples: n_samples=\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m         )\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    338\u001b[0m     )\n\u001b[0;32m--> 340\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m    341\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py:86\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     84\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m     85\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(_num_samples(X))\n\u001b[0;32m---> 86\u001b[0m \u001b[39mfor\u001b[39;00m test_index \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[1;32m     87\u001b[0m     train_index \u001b[39m=\u001b[39m indices[np\u001b[39m.\u001b[39mlogical_not(test_index)]\n\u001b[1;32m     88\u001b[0m     test_index \u001b[39m=\u001b[39m indices[test_index]\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py:713\u001b[0m, in \u001b[0;36mStratifiedKFold._iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_iter_test_masks\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, groups\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 713\u001b[0m     test_folds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_test_folds(X, y)\n\u001b[1;32m    714\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits):\n\u001b[1;32m    715\u001b[0m         \u001b[39myield\u001b[39;00m test_folds \u001b[39m==\u001b[39m i\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/model_selection/_split.py:656\u001b[0m, in \u001b[0;36mStratifiedKFold._make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    654\u001b[0m allowed_target_types \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    655\u001b[0m \u001b[39mif\u001b[39;00m type_of_target_y \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_target_types:\n\u001b[0;32m--> 656\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    657\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSupported target types are: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    658\u001b[0m             allowed_target_types, type_of_target_y\n\u001b[1;32m    659\u001b[0m         )\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m y \u001b[39m=\u001b[39m column_or_1d(y)\n\u001b[1;32m    664\u001b[0m _, y_idx, y_inv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y, return_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_inverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'unknown' instead."
     ]
    }
   ],
   "source": [
    "## Hyper-parameters grid search for Decision Tree\n",
    "\n",
    "hyp_dict = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_impurity_decrease': [0, 1, 1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "combinations = itertools.product(*(hyp_dict[key] for key in sorted(hyp_dict)))\n",
    "\n",
    "results = []\n",
    "\n",
    "for criterion, min_impurity_decrease, min_samples_leaf in combinations:\n",
    "    model = tree.DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        min_impurity_decrease=min_impurity_decrease,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=0\n",
    "    )\n",
    "    mean_val_score, std_val_score = cross_validation_summary(model, x, y, 5)\n",
    "    res = criterion, min_impurity_decrease, min_samples_leaf, mean_val_score, std_val_score\n",
    "    results.append(res)\n",
    "\n",
    "decision_tree_results_df = pd.DataFrame(results, columns=['criterion', 'min_impurity_decrease', 'min_samples_leaf', 'mean_val_score', 'std_val_score'])\n",
    "decision_tree_results_df.sort_values('mean_val_score').tail(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
